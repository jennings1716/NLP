{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "    How to program computers to process and analyze large amount of Natural Language Data\n",
    "\n",
    "\n",
    "## Spacy \n",
    "\n",
    "Library designed to effectively handle NLP tasks with common implementation of Algorithms.\n",
    "\n",
    "It has only the most efficient state of art algorithms and we have no choice of using other algorithms\n",
    "\n",
    "- pip install spacy\n",
    "\n",
    "- python -m spacy download en\n",
    "\n",
    "\n",
    "## NLTK\n",
    "\n",
    "opensource library older than spacy.\n",
    "\n",
    "has many implementations of algorithms which are less efficient.\n",
    "\n",
    "Spacy is **Faster** than NLTK\n",
    "\n",
    "Spacy **does not include sentiment analysis** which are the easy tasks for NLTK.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy Basics\n",
    "\n",
    "**Steps for working with Spacy**\n",
    "    1. Loading the language library \n",
    "    2. Building pipeline object\n",
    "            - The nlp() function from spacy automatically takes raw text and performs the series of operations to tag,parse\n",
    "            and describe the text data.\n",
    "        \n",
    "            -\n",
    "    3. Using Tokens\n",
    "    4. Parts-of-speech Tagging.\n",
    "    5. Understanding Token Attributes\n",
    "    \n",
    "## Working with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is VERB aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "6 NUM compound\n",
      "million NUM pobj\n"
     ]
    }
   ],
   "source": [
    "# Import spaCy and load the language library\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm') #1. Loading the small version of the english core library\n",
    "\n",
    "# Create a Doc object\n",
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million') #2. create the  pipeline Object\n",
    "\n",
    "# Print each token separately\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
